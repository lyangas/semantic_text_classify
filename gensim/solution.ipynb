{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Поставленная задача:<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "R6XZvG5QQKYE"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gensim.models import FastText\n",
    "import fasttext\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-MQECPNRIUr"
   },
   "source": [
    "<h1>1. Создаем датасет<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "X5uATKoN5mbG",
    "outputId": "0f2f854b-e6b1-41a9-ba5e-6f669380907a"
   },
   "outputs": [],
   "source": [
    "# создаем датасет\n",
    "\n",
    "def clear_text(text):\n",
    "    \"\"\"\n",
    "        функция для очистки текста:\n",
    "            приведение к нижнему регистру\n",
    "            замена «ё» на «е»\n",
    "            замена ссылок на токен «URL»\n",
    "            замена упоминания пользователя на токен «USER»\n",
    "            удаление знаков препинания\n",
    "    \"\"\"\n",
    "    text = text.lower().replace(\"ё\", \"е\")\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'url', text)\n",
    "    text = re.sub('@[^\\s]+', 'user', text)\n",
    "\n",
    "    text = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# считываем данные\n",
    "n = ['id', 'date', 'name', 'text', 'typr', 'rep', 'rtw', 'faw', 'stcount', 'foll', 'frien', 'listcount']\n",
    "data_positive = pd.read_csv('data/positive.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])\n",
    "data_negative = pd.read_csv('data/negative.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])\n",
    "\n",
    "# формируем датасет\n",
    "raw_data = np.concatenate([data_positive['text'].values, data_negative['text'].values])\n",
    "texts = [clear_text(text) for text in raw_data] # чиcтим тексты\n",
    "labels = np.array([1] * data_positive.shape[0] + [0] * data_negative.shape[0])\n",
    "\n",
    "# делим датасет на train/test\n",
    "texts_train, texts_test, y_train, y_test = train_test_split(texts, labels, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bggzGz07VCRd"
   },
   "source": [
    "<h1>2. Обучение<h1>\n",
    "\n",
    "<h2>2.1 fasttext от gensim<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xpzfplsk0ENB"
   },
   "outputs": [],
   "source": [
    "# приводим датасет к виду, необходимому для обучения модели\n",
    "dataset_for_ft = [text.split(' ') for text in texts_train]\n",
    "\n",
    "# строим вокубуляр токенов\n",
    "ft_gensim_model = FastText(size=100, window=3, min_count=1)\n",
    "ft_gensim_model.build_vocab(dataset_for_ft)\n",
    "total_words = ft_gensim_model.corpus_total_words\n",
    "\n",
    "# обучаем w2v-модель\n",
    "ft_gensim_model.train(dataset_for_ft, total_words=total_words, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UV3TjIxwRVTt"
   },
   "outputs": [],
   "source": [
    "# находим имбеддинги всех текстов\n",
    "\n",
    "def text2vec(text):\n",
    "\n",
    "    vecs = []\n",
    "    for word in text.split(' '):\n",
    "        try:\n",
    "            vecs.append(ft_gensim_model.wv[word])  \n",
    "        except Exception as e:\n",
    "            pass      \n",
    "    mean_vec = np.array(vecs).mean(0)\n",
    "\n",
    "    return mean_vec\n",
    "\n",
    "x_train = [text2vec(x) for x in texts_train]\n",
    "x_test = [text2vec(x) for x in texts_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWodCfVJV0-R"
   },
   "source": [
    "Результаты для fasttext от gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "EFq02LZyb7rU",
    "outputId": "6f64235f-2e6b-4eb9-f98b-bf2e4c16c160",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression accuracy on test: 0.6900899312290601\n",
      "naive bayes accuracy on test: 0.6326926467995062\n"
     ]
    }
   ],
   "source": [
    "# обучаем логистическую регрессию\n",
    "clf_logreg = LogisticRegression(random_state=0, max_iter=200).fit(x_train, y_train)\n",
    "\n",
    "# смотрим результат на test-выборке\n",
    "pred = clf_logreg.predict(x_test)\n",
    "print('logistic regression accuracy on test: {}'.format(1 - np.abs(pred - y_test).sum() / len(y_test)))\n",
    "\n",
    "\n",
    "# обучаем наивный байес\n",
    "clf_naive_b = GaussianNB().fit(x_train, y_train)\n",
    "\n",
    "# смотрим результат на test-выборке\n",
    "pred = clf_naive_b.predict(x_test)\n",
    "print('naive bayes accuracy on test: {}'.format(1 - np.abs(pred - y_test).sum() / len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX6JmgiUb15p"
   },
   "source": [
    "<h2>2.2 fasttext от facebook<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YGLZahcMPJ05"
   },
   "outputs": [],
   "source": [
    "# приводим датасет к виду, необходимому для обучения модели\n",
    "\n",
    "with open('ft_dataset.txt', 'w') as f:\n",
    "    f.write('\\n\\n'.join(texts_train))\n",
    "\n",
    "# обучаем w2v-модель\n",
    "ft_fb_model = fasttext.train_unsupervised(input=\"ft_dataset.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vdsFuQFsc3Vu"
   },
   "outputs": [],
   "source": [
    "# находим имбеддинги всех текстов\n",
    "\n",
    "def text2vec(text):\n",
    "\n",
    "    vecs = []\n",
    "    for word in text.split(' '):\n",
    "        try:\n",
    "            vecs.append(ft_fb_model.get_word_vector(word))  \n",
    "        except Exception as e:\n",
    "            pass      \n",
    "    mean_vec = np.array(vecs).mean(0)\n",
    "\n",
    "    return mean_vec\n",
    "    \n",
    "x_train = [text2vec(x) for x in texts_train]\n",
    "x_test = [text2vec(x) for x in texts_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmM9Us64WJP0"
   },
   "source": [
    "Результаты для fasttext от facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "ES2iUdK0RJ-d",
    "outputId": "c41579a6-2cf6-4308-ad83-988b70d06cc4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression accuracy on test: 0.7240786457414918\n",
      "naive bayes accuracy on test: 0.685946041262564\n"
     ]
    }
   ],
   "source": [
    "# обучаем логистическую регрессию\n",
    "clf_logreg = LogisticRegression(random_state=0, max_iter=200).fit(x_train, y_train)\n",
    "\n",
    "# смотрим результат на test-выборке\n",
    "pred = clf_logreg.predict(x_test)\n",
    "print('logistic regression accuracy on test: {}'.format(1 - np.abs(pred - y_test).sum() / len(y_test)))\n",
    "\n",
    "\n",
    "# обучаем наивный байес\n",
    "clf_naive_b = GaussianNB().fit(x_train, y_train)\n",
    "\n",
    "# смотрим результат на test-выборке\n",
    "pred = clf_naive_b.predict(x_test)\n",
    "print('naive bayes accuracy on test: {}'.format(1 - np.abs(pred - y_test).sum() / len(y_test)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
